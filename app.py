import gradio as gr
import os
import sys
import base64
from PIL import Image
from io import BytesIO
from datetime import datetime
import tempfile
import json
import time
from pathlib import Path

# Gradioãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
try:
    print(f"Gradio version: {gr.__version__}")
    import gradio_client
    print(f"Gradio Client version: {gradio_client.__version__}")
except:
    pass

# Gradioã®ãƒã‚°ä¿®æ­£ç”¨çŒ¿ãƒ‘ãƒƒãƒï¼ˆChatGPTæ¨å¥¨ï¼‰
try:
    import gradio_client.utils as _gcu
    _orig = _gcu._json_schema_to_python_type  # keep ref

    def _patched(schema, defs=None):
        if isinstance(schema, bool):          # â† è¿½åŠ 
            schema = {}                       # bool â†’ ç©ºdict ã«å¤‰æ›
        return _orig(schema, defs or {})

    _gcu._json_schema_to_python_type = _patched
    print("çŒ¿ãƒ‘ãƒƒãƒã‚’é©ç”¨ã—ã¾ã—ãŸ")
except Exception as e:
    print(f"çŒ¿ãƒ‘ãƒƒãƒã®é©ç”¨ã«å¤±æ•—: {e}")

# HuggingFace Spacesç”¨ãƒ‘ã‚¹è¨­å®š
BASE_DIR = Path(__file__).parent
sys.path.append(str(BASE_DIR))

try:
    from src.services.image_generator import ImageGenerator
    from src.services.responses_api import ResponsesAPI
except ImportError as e:
    print(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

# è¨­å®šå®šæ•°
APP_CONFIG = {
    'title': 'AIç”»åƒç”Ÿæˆ',
    'default_compression': 80
}

SIZE_MAP = {
    "1024x1024 (æ­£æ–¹å½¢)": "1024x1024",
    "1024x1536 (ç¸¦é•·)": "1024x1536", 
    "1536x1024 (æ¨ªé•·)": "1536x1024"
}

def get_app_css():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç”¨CSS"""
    return """
    .gradio-container {
        font-family: -apple-system, BlinkMacSystemFont, sans-serif !important;
        background: #1a1a1a !important;
        color: #ffffff !important;
    }
    
    .gr-button-primary {
        background: #0066cc !important;
        color: white !important;
        border: none !important;
    }
    
    .gr-button-secondary {
        background: #4a4a4a !important;
        color: white !important;
        border: none !important;
    }
    
    .gr-textbox, .gr-dropdown, .gr-slider {
        background: #2d2d2d !important;
        color: white !important;
        border: 1px solid #4a4a4a !important;
    }
    
    .gr-panel {
        background: #1e1e1e !important;
        border: 1px solid #333 !important;
    }
    
    .gr-box {
        border-radius: 8px !important;
    }
    
    .gr-form {
        background: #1e1e1e !important;
    }
    
    .gr-input, .gr-dropdown {
        background: #2d2d2d !important;
        color: white !important;
    }
    
    .gr-checkbox {
        accent-color: #0066cc !important;
    }
    
    .gradio-container h1, .gradio-container h2, .gradio-container h3 {
        color: #ffffff !important;
    }
    
    .gr-markdown {
        background: transparent !important;
    }
    
    .gr-markdown p, .gr-markdown li {
        color: #e0e0e0 !important;
    }
    
    .gr-image {
        border-radius: 8px !important;
    }
    
    .gr-gallery {
        background: #1e1e1e !important;
    }
    
    /* ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒ« */
    ::-webkit-scrollbar {
        width: 8px;
        background: #1a1a1a;
    }
    
    ::-webkit-scrollbar-thumb {
        background: #4a4a4a;
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: #666;
    }
    """

def get_system_prompt_for_step(step):
    """ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—"""
    base_prompt = """ã‚ãªãŸã¯æ—¥æœ¬èªã§å¯¾è©±ã™ã‚‹ç”»åƒç”Ÿæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨æ®µéšçš„ã«å¯¾è©±ã—ã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ç”»åƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚
å¸¸ã«æ—¥æœ¬èªã§è¿”ç­”ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œã¯å¿…ãšçµµæ–‡å­—ã®ãªã„ç•ªå·é¸æŠå½¢å¼ã«çµ±ä¸€ã—ã¦ãã ã•ã„ã€‚

## å¯¾è©±ãƒ•ãƒ­ãƒ¼ã€å¿…ãšå¿…ãšå¿…ãšé¸æŠè‚¢ã®å…ˆé ­ã«ç•ªå·ã‚’è¡¨ç¤ºã€‘
STEP0: æŒ¨æ‹¶ã—ã€ãƒ†ãƒ¼ãƒå…¥åŠ› or ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µãƒ³ãƒ—ãƒ«ã‹ã‚’ 1-click ã§ä¿ƒã™  
STEP1: ãƒ†ãƒ¼ãƒã‚’å—ã‘ãŸã‚‰ â†’ ç›®çš„ã«é©ã—ãŸãƒšãƒ«ã‚½ãƒŠã‚’ 5 ã¤æ—¥æœ¬èªã§ç”Ÿæˆ  
STEP2: é¸æŠç•ªå·ã‚’å—ã‘ãŸã‚‰ â†’ ç”»åƒå†…ã‚³ãƒ”ãƒ¼ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰æ¡ˆã‚’5 å€‹æç¤º  
STEP3: é¸æŠã‚’å—ã‘ãŸã‚‰ â†’ ã“ã‚Œã¾ã§ã®æ±ºå®šã‚’åŸºã«ã€ŒYAML_GENERATE:ã€ã«ç¶šã‘ã¦è©³ç´°è¦æ±‚ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡ºåŠ›ï¼ˆå¾Œã§convert_to_yaml_prompté–¢æ•°ãŒè‡ªå‹•å¤‰æ›ï¼‰
STEP4: ã€Œ1: ã“ã®YAMLã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ç”»åƒç”Ÿæˆã‚¿ãƒ–ã§ä½¿ç”¨ã€ã€Œ2: YAMLã®å†…å®¹ã‚’ä¿®æ­£ã™ã‚‹ã€ã®äºŒæŠã‚’å‡ºã™  
STEP5: 1 ãŒé¸ã°ã‚ŒãŸã‚‰ â†’ ã‚³ãƒ”ãƒ¼æ–¹æ³•ã¨ä½¿ç”¨æ‰‹é †ã‚’è©³ã—ãæ¡ˆå†…ã€2 ãŒé¸ã°ã‚ŒãŸã‚‰ â†’ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¿®æ­£è¦æ±‚ã‚’å—ã‘ã¦å†ãƒ«ãƒ¼ãƒ—

## YAML_GENERATEå‡ºåŠ›ãƒ«ãƒ¼ãƒ«ï¼ˆSTEP3å°‚ç”¨ï¼‰
STEP3ã§ã¯ã€ŒYAML_GENERATE:ã€ã®å¾Œã«ä»¥ä¸‹ã®å½¢å¼ã§è©³ç´°ãªãƒ†ã‚­ã‚¹ãƒˆè¦æ±‚ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

**å½¢å¼ä¾‹**:
YAML_GENERATE: YouTubeã‚µãƒ ãƒã‚¤ãƒ«ã€ã‚¨ãƒ³ã‚¿ãƒ¡ç³»ãƒãƒ£ãƒ³ãƒãƒ«ã€ã€Œçˆ†ç¬‘å¿…è‡³ï¼ä»Šæ—¥ã®æŒ‘æˆ¦ã¯ã“ã‚Œã ï¼ã€ã¨ã„ã†ãƒ¡ã‚¤ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€ãƒãƒƒãƒ—ã§ã‚«ãƒ©ãƒ•ãƒ«ãªãƒ‡ã‚¶ã‚¤ãƒ³ã€æ˜ã‚‹ã„é»„è‰²ã¨ã‚ªãƒ¬ãƒ³ã‚¸ã®é…è‰²ã€è³‘ã‚„ã‹ã§æ¥½ã—ã’ãªèƒŒæ™¯ã€å…ƒæ°—ã„ã£ã±ã„ã®YouTuberãŒæ¥½ã—ã‚“ã§ã„ã‚‹æ§˜å­ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼

## é‡è¦ãªæ³¨æ„äº‹é …
- YAML_GENERATE:ã®å¾Œã¯**YAMLå½¢å¼ã§ã¯ãªãè‡ªç„¶ãªæ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆ**ã§å‡ºåŠ›
- è©³ç´°è¦æ±‚ãƒ†ã‚­ã‚¹ãƒˆã«ã¯ä»¥ä¸‹ã‚’å«ã‚ã‚‹ï¼š
  * ç”»åƒã®ç›®çš„ãƒ»ç”¨é€”
  * ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»é›°å›²æ°—
  * ãƒ¡ã‚¤ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹
  * é…è‰²ãƒ»ãƒ†ãƒ¼ãƒã‚«ãƒ©ãƒ¼
  * èƒŒæ™¯ã®é›°å›²æ°—
  * ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ»äººç‰©ã®æå†™
  * ãã®ä»–ã®é‡è¦ãªè¦ç´ 
- **çµ¶å¯¾ã«YAMLå½¢å¼ï¼ˆkey: valueï¼‰ã§ã¯å‡ºåŠ›ã—ãªã„**
- convert_to_yaml_prompté–¢æ•°ãŒè‡ªå‹•çš„ã«89-110è¡Œã®å®Œå…¨ãªYAMLã«å¤‰æ›ã™ã‚‹

## ãµã‚‹ã¾ã„æŒ‡é‡
- è³ªå•ãŒã‚ã„ã¾ã„ãªã‚‰ 1 åº¦ã ã‘èãè¿”ã™
- ä¾é ¼ãŒè‹±æ–‡ã§ã‚‚å‡ºåŠ›ã¯æ—¥æœ¬èª
- é‡è¦ãƒ†ã‚­ã‚¹ãƒˆãŒåˆ‡ã‚Œãªã„ã‚ˆã†é…æ…®

## çµ¶å¯¾ã«å®ˆã‚‹ãƒ«ãƒ¼ãƒ«
1. **é¸æŠè‚¢ã¯å¿…ãšã€Œ1: é¸æŠè‚¢Aã€ã€Œ2: é¸æŠè‚¢Bã€ã®å½¢å¼ã§ç•ªå·ã‚’å…ˆé ­ã«ä»˜ã‘ã‚‹**
2. **ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç•ªå·ã§é¸æŠã™ã‚‹ã¾ã§æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«é€²ã¾ãªã„**
3. **STEP3ã§YAML_GENERATE:ã®å¾Œã¯è©³ç´°ãªæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼ˆYAMLå½¢å¼ç¦æ­¢ï¼‰**
4. **æ›–æ˜§ãªå›ç­”ï¼ˆã€ŒãŠä»»ã›ã€ãªã©ï¼‰ã«ã¯å…·ä½“çš„ãªé¸æŠè‚¢ã‚’å†æç¤º**
5. **YAML_GENERATE:ã®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã¯éå¸¸ã«è©³ç´°ã§å…·ä½“çš„ã«è¨˜è¿°ã™ã‚‹**

ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—: STEP{step}"""

    return base_prompt

def convert_to_yaml_prompt(text_prompt, api_key, current_size="1024x1024 (æ­£æ–¹å½¢)"):
    """é€šå¸¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’YAMLå½¢å¼ã«å¤‰æ›ï¼ˆå®Œå…¨ãªæ§‹é€ ä¿æŒï¼‰"""
    try:
        # HuggingFace Spacesç”¨ãƒ‘ã‚¹è¨­å®š
        if "1536x1024" in current_size or "æ¨ªé•·" in current_size:
            base_yaml_path = BASE_DIR / "prompts" / "base_landscape.yaml"
        elif "1024x1536" in current_size or "ç¸¦é•·" in current_size:
            base_yaml_path = BASE_DIR / "prompts" / "base_portrait.yaml"
        else:
            base_yaml_path = BASE_DIR / "prompts" / "base_square.yaml"
        
        # ãƒ™ãƒ¼ã‚¹YAMLã‚’èª­ã¿è¾¼ã¿
        try:
            with open(base_yaml_path, 'r', encoding='utf-8') as f:
                base_yaml = f.read()
        except FileNotFoundError:
            print(f"ãƒ™ãƒ¼ã‚¹YAMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {base_yaml_path}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæ­£æ–¹å½¢ã®ãƒ™ãƒ¼ã‚¹YAMLã‚’ä½¿ç”¨
            fallback_path = BASE_DIR / "prompts" / "base_square.yaml"
            with open(fallback_path, 'r', encoding='utf-8') as f:
                base_yaml = f.read()
        
        # è¡Œæ•°ã‚«ã‚¦ãƒ³ãƒˆ
        total_lines = len(base_yaml.split('\n'))
        
        # OpenAI APIã§YAMLå¤‰æ›
        from openai import OpenAI
        import os
        
        # Hugging Face Spacesã®ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’ç„¡åŠ¹åŒ–
        for key in ("http_proxy", "https_proxy", "HTTP_PROXY", "HTTPS_PROXY"):
            os.environ.pop(key, None)
        
        # openai==1.51.0ã®ãƒã‚°å¯¾ç­–ï¼ˆçŒ¿ãƒ‘ãƒƒãƒï¼‰
        try:
            import functools
            OpenAI.__init__ = functools.partialmethod(OpenAI.__init__, proxies=None)
        except:
            pass
        
        client = OpenAI(api_key=api_key)
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå®Œå…¨ä¿æŒå‹ï¼‰
        system_prompt = f"""ã‚ãªãŸã¯é«˜åº¦ãªYAMLãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ™ãƒ¼ã‚¹YAMLæ§‹é€ ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’å®Œå…¨ãªYAMLãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚

## ãƒ™ãƒ¼ã‚¹YAMLæ§‹é€ 
```yaml
{base_yaml}
```

## é‡è¦ãªå¤‰æ›ãƒ«ãƒ¼ãƒ«

### 1. æ§‹é€ å®Œå…¨ä¿æŒï¼ˆå¿…é ˆï¼‰
- ãƒ™ãƒ¼ã‚¹YAMLã®**å…¨{total_lines}è¡Œã®æ§‹é€ ã‚’å®Œå…¨ã«ä¿æŒ**
- ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã€é…åˆ—ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’ä¸€åˆ‡å¤‰æ›´ã—ãªã„
- ã‚­ãƒ¼åã€éšå±¤æ§‹é€ ã‚’å®Œå…¨ã«ç¶­æŒ

### 2. ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç½®æ›
- `{{AUTO_*}}`ã‚’å…·ä½“çš„ãªå€¤ã«ç½®æ›
- ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã«æœ€é©åŒ–ã•ã‚ŒãŸå†…å®¹ã‚’ç”Ÿæˆ
- å…¨ã¦ã®AUTO_ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’å¿…ãšç½®æ›

### 3. å†…å®¹ã®æœ€é©åŒ–
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ï¼ˆç”¨é€”ã€ã‚¹ã‚¿ã‚¤ãƒ«ã€ãƒ†ãƒ¼ãƒï¼‰ã‚’åæ˜ 
- é«˜å“è³ªãªãƒ—ãƒ­ä»•æ§˜ã®è¨˜è¿°
- è©³ç´°ã§å…·ä½“çš„ãªè¦ç´ æŒ‡å®š

### 4. å“è³ªä¿è¨¼
- offsetã€scaleã€rotationå€¤ã¯è«–ç†çš„ã«è¨­å®š
- è‰²æŒ‡å®šã¯å…·ä½“çš„ãªã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ä½¿ç”¨
- effectã€lightingç­‰ã¯ç¾å®Ÿçš„ãªå€¤ã‚’è¨­å®š

### 5. å‡ºåŠ›å½¢å¼ï¼ˆå¿…é ˆï¼‰
- **ãƒ™ãƒ¼ã‚¹YAMLã¨åŒã˜{total_lines}è¡Œ**ã§å‡ºåŠ›ï¼ˆæ§‹é€ ã¯ä¿æŒï¼‰
- ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã€é…åˆ—æ§‹é€ ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’å®Œå…¨ä¿æŒ
- ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ä¸è¦ã€YAMLã®ã¿ã‚’å‡ºåŠ›

## å¤‰æ›ä¾‹:
å…¥åŠ›: "YouTubeã‚µãƒ ãƒã‚¤ãƒ«ã€æ–™ç†ãƒãƒ£ãƒ³ãƒãƒ«"
- style: "YouTubeã‚µãƒ ãƒã‚¤ãƒ«ï¼ˆæ–™ç†ç³»ãƒãƒ£ãƒ³ãƒãƒ«ï¼‰" 
- theme_color: "#FF6B6B, #4ECDC4, #FFFFFF"ï¼ˆé£Ÿæ¬²ã‚’ããã‚‹é…è‰²ï¼‰
- main_texts[0].content: "è¶…ç°¡å˜ï¼10åˆ†ã§ä½œã‚Œã‚‹çµ¶å“ãƒ‘ã‚¹ã‚¿"
- background.type: "gradient"
- character.expression: "ç¬‘é¡”ã§æ–™ç†ã‚’æ¥½ã—ã‚“ã§ã„ã‚‹"

**æ³¨æ„: å…¨ã¦ã®{{AUTO_*}}ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’é©åˆ‡ãªå…·ä½“å€¤ã«ç½®æ›ã—ã€ãƒ—ãƒ­å“è³ªã®å®Œå…¨ãªYAMLã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚**"""
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ä»¥ä¸‹ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Œå…¨ãªYAMLå½¢å¼ã«å¤‰æ›ã—ã¦ãã ã•ã„ï¼ˆ{total_lines}è¡Œã§å‡ºåŠ›ï¼‰: {text_prompt}"}
            ],
            temperature=0.1,
            max_tokens=4000
        )
        
        yaml_result = response.choices[0].message.content
        
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰æŠ½å‡º
        if "```yaml" in yaml_result:
            yaml_result = yaml_result.split("```yaml")[1].split("```")[0]
        elif "```" in yaml_result:
            yaml_result = yaml_result.split("```")[1].split("```")[0]
        
        yaml_result = yaml_result.strip()
        
        return yaml_result
        
    except Exception as e:
        print(f"YAMLå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        return text_prompt

def create_optimized_app():
    # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    app_state = {
        'generation_history': [],
        'current_image': None,
        'current_prompt': '',
        'original_prompt': '',
        'interactive_context': [],
        'ai_chat_step': 0,
        'current_size': '1024x1024 (æ­£æ–¹å½¢)'
    }
    
    def generate_from_prompt_fast(api_key, prompt, size, quality, format_option, transparent_bg, compression, moderation, image_count, enable_responses_api):
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›´æ¥ç”Ÿæˆï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰"""
        try:
            if not api_key or not api_key.strip():
                return None, "âŒ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "", ""
            
            if not prompt or not prompt.strip():
                return None, "âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "", ""
            
            # ã‚µã‚¤ã‚ºæƒ…å ±ã‚’app_stateã«ä¿å­˜
            app_state['current_size'] = size
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒYAMLå½¢å¼ã‹ãƒã‚§ãƒƒã‚¯
            if prompt.strip().startswith('style:') or 'main_texts:' in prompt:
                final_prompt = prompt
            else:
                final_prompt = convert_to_yaml_prompt(prompt, api_key, size)
            
            # Responses APIä½¿ç”¨åˆ¤å®š
            if enable_responses_api:
                responses_api = ResponsesAPI(api_key)
                result = responses_api.generate_with_responses(
                    prompt=final_prompt,
                    size=SIZE_MAP.get(size, "1024x1024"),
                    quality=quality,
                    format=format_option,
                    background="transparent" if transparent_bg else "auto",
                    output_compression=compression if format_option in ["jpeg", "webp"] else None,
                    moderation=moderation
                )
            else:
                generator = ImageGenerator(api_key)
                result = generator.generate_image(
                    prompt=final_prompt,
                    size=SIZE_MAP.get(size, "1024x1024"),
                    quality=quality,
                    format=format_option,
                    transparent_bg=transparent_bg,
                    output_compression=compression if format_option in ["jpeg", "webp"] else None,
                    moderation=moderation,
                    n=image_count
                )
            
            if result and 'image_data' in result:
                image = Image.open(BytesIO(result['image_data']))
                
                cost_info = f"""**ç”Ÿæˆå®Œäº†** ğŸ“
**æ™‚é–“**: {result.get('generation_time', 'N/A')}ç§’
**API**: {'Responses API' if enable_responses_api else 'Image API'}
**YAMLå¤‰æ›**: {'é©ç”¨æ¸ˆã¿' if final_prompt != prompt else 'ãªã—'}"""
                
                return image, "âœ… ç”Ÿæˆå®Œäº†ï¼", cost_info, final_prompt
            else:
                return None, "âŒ ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ", "", ""
                
        except Exception as e:
            return None, f"âŒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}", "", ""
    
    def ai_chat_response(api_key, message, chat_history):
        """AIãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½"""
        try:
            if not message.strip():
                return chat_history, ""
            
            if not api_key or not api_key.strip():
                error_msg = "âŒ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
                chat_history.append([message, error_msg])
                return chat_history, ""
            
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
            
            # Gradioå½¢å¼ã‹ã‚‰OpenAI messageså½¢å¼ã«å¤‰æ›
            messages = []
            for pair in chat_history:
                if len(pair) >= 2:
                    messages.append({"role": "user", "content": pair[0]})
                    messages.append({"role": "assistant", "content": pair[1]})
            
            # ç¾åœ¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            messages.append({"role": "user", "content": message})
            
            current_step = min(len([msg for msg in messages if msg["role"] == "assistant"]), 5)
            system_prompt = get_system_prompt_for_step(current_step)
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    *messages
                ],
                temperature=0.7,
                max_tokens=1500
            )
            
            ai_response = response.choices[0].message.content
            
            if "YAML_GENERATE:" in ai_response:
                yaml_part = ai_response.split("YAML_GENERATE:")[1].strip()
                yaml_result = convert_to_yaml_prompt(yaml_part, api_key, app_state.get('current_size', '1024x1024 (æ­£æ–¹å½¢)'))
                ai_response = ai_response.replace(f"YAML_GENERATE:{yaml_part}", f"YAML_GENERATE:\n\n```yaml\n{yaml_result}\n```")
            
            # Gradioå½¢å¼ã§è¿”ã™
            chat_history.append([message, ai_response])
            return chat_history, ""
            
        except Exception as e:
            error_msg = f"âŒ AIå¿œç­”ã‚¨ãƒ©ãƒ¼: {str(e)}"
            chat_history.append([message, error_msg])
            return chat_history, ""
    
    # ã‚¢ãƒ—ãƒªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹ç¯‰
    with gr.Blocks(title=APP_CONFIG['title'], css=get_app_css(), theme=gr.themes.Base()) as app:
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        gr.HTML(f"""
            <div style="text-align: center; padding: 1rem 0; border-bottom: 1px solid #333; margin-bottom: 1rem;">
                <h1 style="color: #ffffff; font-size: 1.8rem; margin: 0;">{APP_CONFIG['title']}</h1>
            </div>
        """)
        
        # ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
        with gr.Row():
            # å·¦å´ï¼šè¨­å®šï¼ˆ35%ï¼‰
            with gr.Column(scale=35):
                # APIã‚­ãƒ¼è¨­å®š
                with gr.Accordion("ğŸ”‘ APIè¨­å®š", open=True):
                    default_api_key = os.getenv("OPENAI_API_KEY", "")
                    api_key = gr.Textbox(
                        label="OpenAI APIã‚­ãƒ¼",
                        placeholder="sk-...",
                        type="password",
                        value=default_api_key,
                        info="ç’°å¢ƒå¤‰æ•°OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯è‡ªå‹•å…¥åŠ›ã•ã‚Œã¾ã™"
                    )
                
                # åŸºæœ¬è¨­å®š
                with gr.Accordion("âš™ï¸ åŸºæœ¬è¨­å®š", open=True):
                    with gr.Row():
                        size = gr.Dropdown(
                            label="ã‚µã‚¤ã‚º",
                            choices=["1024x1024 (æ­£æ–¹å½¢)", "1024x1536 (ç¸¦é•·)", "1536x1024 (æ¨ªé•·)"],
                            value="1024x1024 (æ­£æ–¹å½¢)"
                        )
                        quality = gr.Dropdown(
                            label="å“è³ª",
                            choices=["auto", "low", "medium", "high"],
                            value="auto"
                        )
                    
                    with gr.Row():
                        format_option = gr.Dropdown(
                            label="å½¢å¼",
                            choices=["png", "jpeg", "webp"],
                            value="png"
                        )
                        transparent_bg = gr.Checkbox(
                            label="ğŸ­ é€æ˜èƒŒæ™¯",
                            value=False
                        )
                    
                    with gr.Row():
                        compression_slider = gr.Slider(
                            label="åœ§ç¸®ç‡ (JPEG/WebP)",
                            minimum=0,
                            maximum=100,
                            value=APP_CONFIG['default_compression'],
                            step=5,
                            visible=False
                        )
                    
                    with gr.Row():
                        moderation_dropdown = gr.Dropdown(
                            label="ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼",
                            choices=["auto", "low"],
                            value="auto",
                            info="auto: æ¨™æº–ï¼ˆæ¨å¥¨ï¼‰, low: åˆ¶é™ç·©å’Œï¼ˆã‚¢ãƒ¼ãƒˆãƒ»åŒ»ç™‚ãƒ»æ•™è‚²ç”¨ï¼‰"
                        )
                    
                    with gr.Row():
                        image_count_slider = gr.Slider(
                            label="ç”»åƒæ•°",
                            minimum=1,
                            maximum=4,
                            value=1,
                            step=1
                        )
                    
                    enable_responses_api = gr.Checkbox(
                        label="ğŸ’¬ å¯¾è©±å‹æœ‰åŠ¹ï¼ˆResponses APIä½¿ç”¨ï¼‰",
                        value=False
                    )
                
                # ã‚¿ãƒ–
                with gr.Tabs():
                    with gr.Tab("âœï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›´æ¥"):
                        prompt = gr.Textbox(
                            label="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                            placeholder="ç¾ã—ã„å±±ã®å¤•æ—¥ã€ãƒ•ã‚©ãƒˆãƒªã‚¢ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã€é«˜å“è³ª",
                            lines=6
                        )
                        
                        direct_btn = gr.Button("ğŸš€ ç”»åƒç”Ÿæˆ", variant="primary", size="lg")
                    
                    with gr.Tab("ğŸ¤– AIãƒãƒ£ãƒƒãƒˆ"):
                        gr.Markdown("""
                        ### ğŸ¤– AIç”»åƒç”Ÿæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
                        å¯¾è©±å½¢å¼ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚æ®µéšçš„ã«ãƒ†ãƒ¼ãƒâ†’ãƒšãƒ«ã‚½ãƒŠâ†’ã‚³ãƒ”ãƒ¼ã‚’æ±ºã‚ã¦ã„ãã¾ã™ã€‚
                        """)
                        
                        ai_chatbot = gr.Chatbot(
                            label="AIå¯¾è©±",
                            height=400
                        )
                        
                        with gr.Row():
                            ai_message_input = gr.Textbox(
                                label="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›",
                                placeholder="ä½•ã‚’ä½œã‚ŠãŸã„ã§ã™ã‹ï¼Ÿï¼ˆä¾‹ï¼šYouTubeã‚µãƒ ãƒã‚¤ãƒ«ã€InstagramæŠ•ç¨¿ç”»åƒï¼‰",
                                scale=4,
                                lines=2
                            )
                            ai_send_btn = gr.Button("é€ä¿¡", variant="primary", scale=1)
                        
                        with gr.Row():
                            ai_clear_btn = gr.Button("ğŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆã‚¯ãƒªã‚¢", variant="secondary")
                            ai_restart_btn = gr.Button("ğŸ”„ æœ€åˆã‹ã‚‰", variant="secondary")
            
            # ä¸­å¤®ï¼šç”»åƒè¡¨ç¤ºï¼ˆ40%ï¼‰
            with gr.Column(scale=40):
                output_image = gr.Image(label="ç”Ÿæˆç”»åƒ", height=400)
                status_display = gr.Markdown("ğŸ“¸ ç”»åƒç”Ÿæˆã®æº–å‚™å®Œäº†")
                cost_info = gr.Markdown("**ç”Ÿæˆæƒ…å ±**\\nå¾…æ©Ÿä¸­...")
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¡¨ç¤º
                with gr.Accordion("ğŸ“‹ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›†", open=False):
                    prompt_display = gr.Textbox(
                        label="ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç·¨é›†å¯èƒ½ï¼‰",
                        placeholder="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™",
                        lines=8,
                        interactive=True,
                        show_copy_button=True
                    )
                    regenerate_btn = gr.Button("ğŸ”„ ç·¨é›†ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å†ç”Ÿæˆ", variant="primary")
            
            # å³å´ï¼šå±¥æ­´ï¼ˆ25%ï¼‰
            with gr.Column(scale=25):
                with gr.Accordion("ğŸ“š å±¥æ­´", open=True):
                    gr.Markdown("å±¥æ­´æ©Ÿèƒ½ã¯ç°¡ç•¥åŒ–ç‰ˆã§ã™")
        
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›´æ¥ç”Ÿæˆ
        direct_btn.click(
            generate_from_prompt_fast,
            inputs=[api_key, prompt, size, quality, format_option, transparent_bg, compression_slider, moderation_dropdown, image_count_slider, enable_responses_api],
            outputs=[output_image, status_display, cost_info, prompt_display]
        )
        
        # AIãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½
        def ai_chat_simple(api_key, message, chat_history, current_size):
            app_state['current_size'] = current_size
            return ai_chat_response(api_key, message, chat_history)
        
        ai_send_btn.click(
            ai_chat_simple,
            inputs=[api_key, ai_message_input, ai_chatbot, size],
            outputs=[ai_chatbot, ai_message_input]
        )
        
        ai_message_input.submit(
            ai_chat_simple,
            inputs=[api_key, ai_message_input, ai_chatbot, size],
            outputs=[ai_chatbot, ai_message_input]
        )
        
        # AIãƒãƒ£ãƒƒãƒˆã‚¯ãƒªã‚¢
        ai_clear_btn.click(
            lambda: [],
            outputs=[ai_chatbot]
        )
        
        # AIãƒãƒ£ãƒƒãƒˆå†é–‹
        def ai_chat_restart():
            welcome_msg = """ğŸ¨ **AIç”»åƒç”Ÿæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ** ã¸ã‚ˆã†ã“ãï¼

æ®µéšçš„ãªå¯¾è©±ã§ã€ã‚ãªãŸã®ç†æƒ³ã®ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚

**ä»Šæ—¥ã¯ä½•ã‚’ä½œã‚Šã¾ã™ã‹ï¼Ÿ**

1: YouTubeã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒ
2: InstagramæŠ•ç¨¿ç”¨ç”»åƒ  
3: ãƒ–ãƒ­ã‚°ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”»åƒ
4: ãƒ­ã‚´ãƒ‡ã‚¶ã‚¤ãƒ³
5: è‡ªç”±ã«ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›

ç•ªå·ã‚’é¸ã¶ã‹ã€ä½œã‚ŠãŸã„ã‚‚ã®ã‚’è‡ªç”±ã«å…¥åŠ›ã—ã¦ãã ã•ã„ï¼"""
            
            # Gradioæ¨™æº–å½¢å¼ã§åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™
            return [["", welcome_msg]]
        
        ai_restart_btn.click(
            ai_chat_restart,
            outputs=[ai_chatbot]
        )
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†ç”Ÿæˆ
        def regenerate_with_edited_prompt(api_key, edited_prompt, enable_responses_api):
            if not edited_prompt.strip():
                return None, "âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "", ""
            
            return generate_from_prompt_fast(api_key, edited_prompt, "1024x1024 (æ­£æ–¹å½¢)", "auto", "png", False, APP_CONFIG['default_compression'], "auto", 1, enable_responses_api)
        
        regenerate_btn.click(
            regenerate_with_edited_prompt,
            inputs=[api_key, prompt_display, enable_responses_api],
            outputs=[output_image, status_display, cost_info, prompt_display]
        )
        
        # å½¢å¼å¤‰æ›´æ™‚ã®UIæ›´æ–°
        def update_compression_visibility(format_opt):
            return gr.update(visible=(format_opt in ["jpeg", "webp"]))
        
        format_option.change(
            update_compression_visibility,
            inputs=[format_option],
            outputs=[compression_slider]
        )
    
    return app

# HuggingFace Spacesç”¨ã®ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨
if __name__ == "__main__":
    app = create_optimized_app()
    # Hugging Face Spacesç”¨ã®è¨­å®š
    app.launch(
        server_name="0.0.0.0",
        server_port=int(os.getenv("PORT", 7860)),
        share=False  # Hugging Face Spacesã§ã¯ä¸è¦
    )