import gradio as gr
import os
import sys
import base64
from PIL import Image
from io import BytesIO
from datetime import datetime
import tempfile
import json
import time
from pathlib import Path

# HuggingFace Spacesç”¨ãƒ‘ã‚¹è¨­å®š
BASE_DIR = Path(__file__).parent
sys.path.append(str(BASE_DIR))

try:
    from src.services.image_generator import ImageGenerator
    from src.services.responses_api import ResponsesAPI
except ImportError as e:
    print(f"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

# è¨­å®šå®šæ•°
APP_CONFIG = {
    'title': 'AIç”»åƒç”Ÿæˆ',
    'default_compression': 80
}

SIZE_MAP = {
    "1024x1024 (æ­£æ–¹å½¢)": "1024x1024",
    "1024x1536 (ç¸¦é•·)": "1024x1536", 
    "1536x1024 (æ¨ªé•·)": "1536x1024"
}

def get_app_css():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç”¨CSS"""
    return """
    .gradio-container {
        font-family: -apple-system, BlinkMacSystemFont, sans-serif !important;
        background: #1a1a1a !important;
        color: #ffffff !important;
    }
    
    .gr-button-primary {
        background: #0066cc !important;
        color: white !important;
        border: none !important;
    }
    
    .gr-button-secondary {
        background: #4a4a4a !important;
        color: white !important;
        border: none !important;
    }
    
    .gr-textbox, .gr-dropdown, .gr-slider {
        background: #2d2d2d !important;
        color: white !important;
        border: 1px solid #4a4a4a !important;
    }
    
    .gr-panel {
        background: #1e1e1e !important;
        border: 1px solid #333 !important;
    }
    
    .gr-box {
        border-radius: 8px !important;
    }
    
    .gr-form {
        background: #1e1e1e !important;
    }
    
    .gr-input, .gr-dropdown {
        background: #2d2d2d !important;
        color: white !important;
    }
    
    .gr-checkbox {
        accent-color: #0066cc !important;
    }
    
    .gradio-container h1, .gradio-container h2, .gradio-container h3 {
        color: #ffffff !important;
    }
    
    .gr-markdown {
        background: transparent !important;
    }
    
    .gr-markdown p, .gr-markdown li {
        color: #e0e0e0 !important;
    }
    
    .gr-image {
        border-radius: 8px !important;
    }
    
    .gr-gallery {
        background: #1e1e1e !important;
    }
    
    /* ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒ« */
    ::-webkit-scrollbar {
        width: 8px;
        background: #1a1a1a;
    }
    
    ::-webkit-scrollbar-thumb {
        background: #4a4a4a;
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: #666;
    }
    """

def create_optimized_app():
    # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    app_state = {
        'generation_history': [],
        'current_image': None,
        'current_prompt': '',
        'original_prompt': '',
        'interactive_context': [],
        'ai_chat_step': 0,
        'current_size': '1024x1024 (æ­£æ–¹å½¢)'
    }
    
    def generate_image_fast(api_key, prompt, size, quality, format_option, transparent_bg, compression, moderation, image_count, enable_responses_api):
        """è©³ç´°è¨­å®šã«ã‚ˆã‚‹ç”»åƒç”Ÿæˆï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰"""
        try:
            if not api_key or not api_key.strip():
                return None, "âŒ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "", ""
            
            if not prompt or not prompt.strip():
                return None, "âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "", ""
            
            # ã‚µã‚¤ã‚ºæƒ…å ±ã‚’app_stateã«ä¿å­˜
            app_state['current_size'] = size
            
            start_time = time.time()
            
            # Responses APIä½¿ç”¨åˆ¤å®š
            if enable_responses_api:
                print(f"[DEBUG] Responses APIä½¿ç”¨: enable_responses_api={enable_responses_api}")
                
                responses_api = ResponsesAPI(api_key)
                result = responses_api.generate_with_responses(
                    prompt=prompt,
                    size=SIZE_MAP.get(size, "1024x1024"),
                    quality=quality,
                    format=format_option,
                    background="transparent" if transparent_bg else "auto",
                    output_compression=compression if format_option in ["jpeg", "webp"] else None,
                    moderation=moderation
                )
                
                if result and 'image_data' in result:
                    image = Image.open(BytesIO(result['image_data']))
                    
                    # å¯¾è©±å‹ç·¨é›†ç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆæœŸåŒ–
                    app_state['interactive_context'] = [
                        {
                            "role": "user", 
                            "content": [
                                {"type": "text", "text": prompt},
                                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{base64.b64encode(result['image_data']).decode()}"}}
                            ]
                        }
                    ]
                    
                    # å±¥æ­´ã«ä¿å­˜
                    history_item = {
                        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M"),
                        'image_data': result['image_data'],
                        'prompt': prompt,
                        'purpose': "é«˜å“è³ªç”Ÿæˆ",
                        'style': f"{quality}å“è³ª"
                    }
                    app_state['generation_history'].append(history_item)
                    app_state['current_image'] = {'image_data': result['image_data'], 'prompt': prompt}
                    app_state['current_prompt'] = prompt
                    app_state['original_prompt'] = prompt
                    
                    # æœ€æ–°3ä»¶ã«åˆ¶é™
                    if len(app_state['generation_history']) > 3:
                        app_state['generation_history'] = app_state['generation_history'][-3:]
                    
                    cost_info = f"""**Responses APIç”Ÿæˆå®Œäº†** ğŸ¯
**æ™‚é–“**: {result.get('generation_time', 'N/A')}ç§’
**API**: OpenAI Responses API  
**å“è³ª**: {quality}
**å¯¾è©±å‹ç·¨é›†**: åˆ©ç”¨å¯èƒ½"""
                    
                    return image, "âœ… é«˜å“è³ªç”Ÿæˆå®Œäº†ï¼å¯¾è©±å‹ç·¨é›†ãŒåˆ©ç”¨å¯èƒ½ã§ã™", cost_info, prompt
                else:
                    return None, "âŒ Responses APIã§ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ", "", ""
            else:
                # å¾“æ¥ã®Image APIä½¿ç”¨
                generator = ImageGenerator(api_key)
                result = generator.generate_image(
                    prompt=prompt,
                    size=SIZE_MAP.get(size, "1024x1024"),
                    quality=quality,
                    format=format_option,
                    transparent_bg=transparent_bg,
                    output_compression=compression if format_option in ["jpeg", "webp"] else None,
                    moderation=moderation,
                    n=image_count
                )
                
                if result and 'image_data' in result:
                    image = Image.open(BytesIO(result['image_data']))
                    
                    # å±¥æ­´ã«ä¿å­˜
                    history_item = {
                        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M"),
                        'image_data': result['image_data'],
                        'prompt': prompt,
                        'purpose': "è©³ç´°è¨­å®šç”Ÿæˆ",
                        'style': f"{quality}å“è³ª"
                    }
                    app_state['generation_history'].append(history_item)
                    app_state['current_image'] = {'image_data': result['image_data'], 'prompt': prompt}
                    app_state['current_prompt'] = prompt
                    app_state['original_prompt'] = prompt
                    
                    # æœ€æ–°3ä»¶ã«åˆ¶é™
                    if len(app_state['generation_history']) > 3:
                        app_state['generation_history'] = app_state['generation_history'][-3:]
                    
                    cost_info = f"""**è©³ç´°è¨­å®šç”Ÿæˆå®Œäº†** âš™ï¸
**æ™‚é–“**: {result.get('generation_time', 'N/A')}ç§’
**API**: OpenAI Image API
**å“è³ª**: {quality}
**ã‚³ã‚¹ãƒˆ**: {result.get('estimated_cost', 'N/A')}"""
                    
                    return image, "âœ… è©³ç´°è¨­å®šç”Ÿæˆå®Œäº†ï¼", cost_info, prompt
                else:
                    return None, "âŒ ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ", "", ""
                    
        except Exception as e:
            error_msg = f"âŒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"
            print(f"[ERROR] generate_image_fast: {e}")
            return None, error_msg, "", ""
    
    def generate_from_prompt_fast(api_key, prompt, size, quality, format_option, transparent_bg, compression, moderation, image_count, enable_responses_api):
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›´æ¥ç”Ÿæˆï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰"""
        try:
            if not api_key or not api_key.strip():
                return None, "âŒ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "", ""
            
            if not prompt or not prompt.strip():
                return None, "âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "", ""
            
            # ã‚µã‚¤ã‚ºæƒ…å ±ã‚’app_stateã«ä¿å­˜
            app_state['current_size'] = size
            
            start_time = time.time()
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒYAMLå½¢å¼ã‹ãƒã‚§ãƒƒã‚¯
            if prompt.strip().startswith('style:') or 'main_texts:' in prompt:
                # YAMLå½¢å¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ãã®ã¾ã¾ä½¿ç”¨
                final_prompt = prompt
            else:
                # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’YAMLå½¢å¼ã«å¤‰æ›
                final_prompt = convert_to_yaml_prompt(prompt, api_key, size)
            
            # Responses APIä½¿ç”¨åˆ¤å®š
            if enable_responses_api:
                print(f"[DEBUG] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›´æ¥ - Responses APIä½¿ç”¨: enable_responses_api={enable_responses_api}")
                
                responses_api = ResponsesAPI(api_key)
                result = responses_api.generate_with_responses(
                    prompt=final_prompt,
                    size=SIZE_MAP.get(size, "1024x1024"),
                    quality=quality,
                    format=format_option,
                    background="transparent" if transparent_bg else "auto",
                    output_compression=compression if format_option in ["jpeg", "webp"] else None,
                    moderation=moderation
                )
                
                if result and 'image_data' in result:
                    image = Image.open(BytesIO(result['image_data']))
                    
                    # å¯¾è©±å‹ç·¨é›†ç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆæœŸåŒ–
                    app_state['interactive_context'] = [
                        {
                            "role": "user", 
                            "content": [
                                {"type": "text", "text": final_prompt},
                                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{base64.b64encode(result['image_data']).decode()}"}}
                            ]
                        }
                    ]
                    
                    # å±¥æ­´ã«ä¿å­˜
                    history_item = {
                        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M"),
                        'image_data': result['image_data'],
                        'prompt': final_prompt,
                        'purpose': "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›´æ¥",
                        'style': f"{quality}å“è³ª"
                    }
                    app_state['generation_history'].append(history_item)
                    app_state['current_image'] = {'image_data': result['image_data'], 'prompt': final_prompt}
                    app_state['current_prompt'] = final_prompt
                    app_state['original_prompt'] = prompt
                    
                    # æœ€æ–°3ä»¶ã«åˆ¶é™
                    if len(app_state['generation_history']) > 3:
                        app_state['generation_history'] = app_state['generation_history'][-3:]
                    
                    cost_info = f"""**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›´æ¥ç”Ÿæˆå®Œäº†** ğŸ“
**æ™‚é–“**: {result.get('generation_time', 'N/A')}ç§’
**API**: OpenAI Responses API
**YAMLå¤‰æ›**: {'é©ç”¨æ¸ˆã¿' if final_prompt != prompt else 'ãªã—'}
**å¯¾è©±å‹ç·¨é›†**: åˆ©ç”¨å¯èƒ½"""
                    
                    return image, "âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›´æ¥ç”Ÿæˆå®Œäº†ï¼å¯¾è©±å‹ç·¨é›†ãŒåˆ©ç”¨å¯èƒ½ã§ã™", cost_info, final_prompt
                else:
                    return None, "âŒ Responses APIã§ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ", "", ""
            else:
                # å¾“æ¥ã®Image APIä½¿ç”¨
                generator = ImageGenerator(api_key)
                result = generator.generate_image(
                    prompt=final_prompt,
                    size=SIZE_MAP.get(size, "1024x1024"),
                    quality=quality,
                    format=format_option,
                    transparent_bg=transparent_bg,
                    output_compression=compression if format_option in ["jpeg", "webp"] else None,
                    moderation=moderation,
                    n=image_count
                )
                
                if result and 'image_data' in result:
                    image = Image.open(BytesIO(result['image_data']))
                    
                    # å±¥æ­´ã«ä¿å­˜
                    history_item = {
                        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M"),
                        'image_data': result['image_data'],
                        'prompt': final_prompt,
                        'purpose': "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›´æ¥",
                        'style': f"{quality}å“è³ª"
                    }
                    app_state['generation_history'].append(history_item)
                    app_state['current_image'] = {'image_data': result['image_data'], 'prompt': final_prompt}
                    app_state['current_prompt'] = final_prompt
                    app_state['original_prompt'] = prompt
                    
                    # æœ€æ–°3ä»¶ã«åˆ¶é™
                    if len(app_state['generation_history']) > 3:
                        app_state['generation_history'] = app_state['generation_history'][-3:]
                    
                    cost_info = f"""**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›´æ¥ç”Ÿæˆå®Œäº†** ğŸ“
**æ™‚é–“**: {result.get('generation_time', 'N/A')}ç§’
**API**: OpenAI Image API
**YAMLå¤‰æ›**: {'é©ç”¨æ¸ˆã¿' if final_prompt != prompt else 'ãªã—'}
**ã‚³ã‚¹ãƒˆ**: {result.get('estimated_cost', 'N/A')}"""
                    
                    return image, "âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›´æ¥ç”Ÿæˆå®Œäº†ï¼", cost_info, final_prompt
                else:
                    return None, "âŒ ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ", "", ""
                    
        except Exception as e:
            error_msg = f"âŒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}"
            print(f"[ERROR] generate_from_prompt_fast: {e}")
            return None, error_msg, "", ""
    
    def continue_interactive_editing(api_key, instruction, interactive_status):
        """å¯¾è©±å‹ç·¨é›†ã®ç¶™ç¶š"""
        try:
            if not api_key or not api_key.strip():
                return None, "âŒ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "", "ğŸ’¬ APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™"
            
            if not instruction or not instruction.strip():
                return None, "âŒ ç·¨é›†æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "", "ğŸ’¬ ç·¨é›†æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
            
            if not app_state.get('interactive_context'):
                return None, "âŒ å¯¾è©±å‹ç·¨é›†ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“", "", "ğŸ’¬ ã¾ãšã€Œå¯¾è©±å‹æœ‰åŠ¹ã€ã§ç”»åƒã‚’ç”Ÿæˆã—ã¦ãã ã•ã„"
            
            # Responses APIã§ç¶™ç¶šç·¨é›†
            responses_api = ResponsesAPI(api_key)
            
            # æ–°ã—ã„æŒ‡ç¤ºã‚’è¿½åŠ 
            app_state['interactive_context'].append({
                "role": "user",
                "content": [{"type": "text", "text": instruction}]
            })
            
            result = responses_api.continue_conversation(
                conversation_history=app_state['interactive_context'],
                new_instruction=instruction
            )
            
            if result and 'image_data' in result:
                image = Image.open(BytesIO(result['image_data']))
                
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°
                app_state['interactive_context'].append({
                    "role": "assistant",
                    "content": [
                        {"type": "text", "text": f"æŒ‡ç¤ºã€Œ{instruction}ã€ã«åŸºã¥ã„ã¦ç”»åƒã‚’ç·¨é›†ã—ã¾ã—ãŸã€‚"},
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{base64.b64encode(result['image_data']).decode()}"}}
                    ]
                })
                
                # å±¥æ­´ã«ä¿å­˜
                history_item = {
                    'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M"),
                    'image_data': result['image_data'],
                    'prompt': f"å¯¾è©±å‹ç·¨é›†: {instruction}",
                    'purpose': "å¯¾è©±å‹ç·¨é›†",
                    'style': "ç¶™ç¶šæ”¹å–„"
                }
                app_state['generation_history'].append(history_item)
                app_state['current_image'] = {'image_data': result['image_data'], 'prompt': instruction}
                
                # æœ€æ–°3ä»¶ã«åˆ¶é™
                if len(app_state['generation_history']) > 3:
                    app_state['generation_history'] = app_state['generation_history'][-3:]
                
                cost_info = f"""**å¯¾è©±å‹ç·¨é›†å®Œäº†** ğŸ’¬
**æ™‚é–“**: {result.get('generation_time', 'N/A')}ç§’
**ç·¨é›†æŒ‡ç¤º**: {instruction[:50]}...
**API**: OpenAI Responses API
**ç¶™ç¶šå¯èƒ½**: ã¯ã„"""
                
                status = f"ğŸ’¬ ç·¨é›†å®Œäº†ï¼ã•ã‚‰ã«ä¿®æ­£æŒ‡ç¤ºã‚’å…¥åŠ›ã§ãã¾ã™ï¼ˆã‚¿ãƒ¼ãƒ³æ•°: {len([msg for msg in app_state['interactive_context'] if msg['role'] == 'user'])}ï¼‰"
                
                return image, "âœ… å¯¾è©±å‹ç·¨é›†å®Œäº†ï¼", cost_info, status
            else:
                return None, "âŒ å¯¾è©±å‹ç·¨é›†ã«å¤±æ•—ã—ã¾ã—ãŸ", "", "ğŸ’¬ ç·¨é›†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å†è©¦è¡Œã—ã¦ãã ã•ã„"
                
        except Exception as e:
            error_msg = f"âŒ å¯¾è©±å‹ç·¨é›†ã‚¨ãƒ©ãƒ¼: {str(e)}"
            print(f"[ERROR] continue_interactive_editing: {e}")
            return None, error_msg, "", "ğŸ’¬ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
    
    def reset_interactive_context():
        """å¯¾è©±å‹ç·¨é›†ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ"""
        app_state['interactive_context'] = []
        return "ğŸ’¬ å¯¾è©±å‹ç·¨é›†ã®å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ"
    
    def generate_with_reference_image_fast(api_key, reference_image, prompt, size, quality, format_option, transparent_bg, compression, moderation):
        """å‚ç…§ç”»åƒã‚’ä½¿ç”¨ã—ãŸç”Ÿæˆï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰"""
        try:
            if not api_key or not api_key.strip():
                return None, "âŒ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "", ""
            
            if reference_image is None:
                return None, "âŒ å‚ç…§ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", "", ""
            
            if not prompt or not prompt.strip():
                return None, "âŒ ç”Ÿæˆã—ãŸã„å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "", ""
            
            # å‚ç…§ç”»åƒç”Ÿæˆã¯ImageGeneratorã‚’ä½¿ç”¨
            generator = ImageGenerator(api_key)
            
            # PIL Imageã‚’BytesIOã«å¤‰æ›
            img_byte_arr = BytesIO()
            reference_image.save(img_byte_arr, format='PNG')
            img_byte_arr = img_byte_arr.getvalue()
            
            result = generator.generate_with_reference_image(
                prompt=prompt,
                reference_image=img_byte_arr,
                size=SIZE_MAP.get(size, "1024x1024"),
                quality=quality,
                format=format_option,
                output_compression=compression if format_option in ["jpeg", "webp"] else None,
                moderation=moderation
            )
            
            if result and 'image_data' in result:
                image = Image.open(BytesIO(result['image_data']))
                
                # ç”Ÿæˆç”»åƒã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as temp_file:
                    image.save(temp_file.name, format='PNG')
                    
                    # å±¥æ­´ã«ä¿å­˜
                    history_item = {
                        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M"),
                        'image_data': result['image_data'],
                        'prompt': f"å‚ç…§ç”»åƒ: {prompt}",
                        'purpose': "ç”»åƒå‚ç…§ç”Ÿæˆ",
                        'style': "å‚ç…§ãƒ™ãƒ¼ã‚¹",
                        'temp_file': temp_file.name
                    }
                    app_state['generation_history'].append(history_item)
                    app_state['current_image'] = {'image_data': result['image_data'], 'prompt': prompt}
                    app_state['current_prompt'] = prompt
                    app_state['original_prompt'] = prompt
                    
                    # æœ€æ–°3ä»¶ã«åˆ¶é™
                    if len(app_state['generation_history']) > 3:
                        app_state['generation_history'] = app_state['generation_history'][-3:]
                    
                    cost_info = f"""**å‚ç…§ç”»åƒç”Ÿæˆå®Œäº†** ğŸ–¼ï¸
**æ™‚é–“**: {result.get('generation_time', 'N/A')}ç§’
**API**: Image Edit API
**ãƒ¢ãƒ¼ãƒ‰**: å‚ç…§ç”»åƒãƒ™ãƒ¼ã‚¹ç”Ÿæˆ"""
                    
                    return image, "âœ… å‚ç…§ç”»åƒç”Ÿæˆå®Œäº†ï¼", cost_info, prompt
                    
        except Exception as e:
            return None, f"âŒ å‚ç…§ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}", "", ""
    
    
    def copy_prompt_to_textbox():
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ”ãƒ¼ç”¨ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«è¡¨ç¤º"""
        if app_state.get('current_prompt'):
            return app_state['current_prompt'], gr.update(visible=True)
        return "ã‚³ãƒ”ãƒ¼ã§ãã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã‚ã‚Šã¾ã›ã‚“", gr.update(visible=False)
    
    def ai_chat_response(api_key, message, chat_history):
        """GPTsãƒ©ã‚¤ã‚¯ãªAIãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ï¼ˆSTEP0-6ãƒ•ãƒ­ãƒ¼ï¼‰"""
        try:
            if not message.strip():
                return chat_history, ""
            
            # APIã‚­ãƒ¼æ¤œè¨¼
            if not api_key or not api_key.strip():
                error_msg = "âŒ APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
                chat_history.append({"role": "user", "content": message})
                chat_history.append({"role": "assistant", "content": error_msg})
                return chat_history, ""
            
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
            
            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ 
            chat_history.append({"role": "user", "content": message})
            
            # ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ¨å®š
            current_step = min(len([msg for msg in chat_history if msg["role"] == "assistant"]), 5)
            
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—
            system_prompt = get_system_prompt_for_step(current_step)
            
            # OpenAI APIã§AIå¿œç­”ç”Ÿæˆ
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    *chat_history
                ],
                temperature=0.7,
                max_tokens=1500
            )
            
            ai_response = response.choices[0].message.content
            
            # YAML_GENERATE:ã®æ¤œå‡ºã¨å¤‰æ›
            if "YAML_GENERATE:" in ai_response:
                yaml_part = ai_response.split("YAML_GENERATE:")[1].strip()
                yaml_result = convert_to_yaml_prompt(yaml_part, api_key, app_state.get('current_size', '1024x1024 (æ­£æ–¹å½¢)'))
                ai_response = ai_response.replace(f"YAML_GENERATE:{yaml_part}", f"YAML_GENERATE:\n\n```yaml\n{yaml_result}\n```")
            
            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«AIå¿œç­”è¿½åŠ 
            chat_history.append({"role": "assistant", "content": ai_response})
            
            return chat_history, ""
            
        except Exception as e:
            error_msg = f"âŒ AIå¿œç­”ã‚¨ãƒ©ãƒ¼: {str(e)}"
            chat_history.append({"role": "assistant", "content": error_msg})
            return chat_history, ""
    
    def convert_to_yaml_prompt(text_prompt, api_key, current_size="1024x1024 (æ­£æ–¹å½¢)"):
        """é€šå¸¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’YAMLå½¢å¼ã«å¤‰æ›ï¼ˆå®Œå…¨ãªæ§‹é€ ä¿æŒï¼‰"""
        try:
            # HuggingFace Spacesç”¨ãƒ‘ã‚¹è¨­å®š
            if "1536x1024" in current_size or "æ¨ªé•·" in current_size:
                base_yaml_path = BASE_DIR / "prompts" / "base_landscape.yaml"
            elif "1024x1536" in current_size or "ç¸¦é•·" in current_size:
                base_yaml_path = BASE_DIR / "prompts" / "base_portrait.yaml"
            else:
                base_yaml_path = BASE_DIR / "prompts" / "base_square.yaml"
            
            # ãƒ™ãƒ¼ã‚¹YAMLã‚’èª­ã¿è¾¼ã¿
            try:
                with open(base_yaml_path, 'r', encoding='utf-8') as f:
                    base_yaml = f.read()
            except FileNotFoundError:
                print(f"ãƒ™ãƒ¼ã‚¹YAMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {base_yaml_path}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæ­£æ–¹å½¢ã®ãƒ™ãƒ¼ã‚¹YAMLã‚’ä½¿ç”¨
                fallback_path = BASE_DIR / "prompts" / "base_square.yaml"
                with open(fallback_path, 'r', encoding='utf-8') as f:
                    base_yaml = f.read()
            
            # è¡Œæ•°ã‚«ã‚¦ãƒ³ãƒˆ
            total_lines = len(base_yaml.split('\n'))
            
            # OpenAI APIã§YAMLå¤‰æ›
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
            
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå®Œå…¨ä¿æŒå‹ï¼‰
            system_prompt = f"""ã‚ãªãŸã¯é«˜åº¦ãªYAMLãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ™ãƒ¼ã‚¹YAMLæ§‹é€ ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’å®Œå…¨ãªYAMLãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ›ã—ã¦ãã ã•ã„ã€‚

## ãƒ™ãƒ¼ã‚¹YAMLæ§‹é€ 
```yaml
{base_yaml}
```

## é‡è¦ãªå¤‰æ›ãƒ«ãƒ¼ãƒ«

### 1. æ§‹é€ å®Œå…¨ä¿æŒï¼ˆå¿…é ˆï¼‰
- ãƒ™ãƒ¼ã‚¹YAMLã®**å…¨{total_lines}è¡Œã®æ§‹é€ ã‚’å®Œå…¨ã«ä¿æŒ**
- ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã€é…åˆ—ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’ä¸€åˆ‡å¤‰æ›´ã—ãªã„
- ã‚­ãƒ¼åã€éšå±¤æ§‹é€ ã‚’å®Œå…¨ã«ç¶­æŒ

### 2. ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç½®æ›
- `{{AUTO_*}}`ã‚’å…·ä½“çš„ãªå€¤ã«ç½®æ›
- ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚ã«æœ€é©åŒ–ã•ã‚ŒãŸå†…å®¹ã‚’ç”Ÿæˆ
- å…¨ã¦ã®AUTO_ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’å¿…ãšç½®æ›

### 3. å†…å®¹ã®æœ€é©åŒ–
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ï¼ˆç”¨é€”ã€ã‚¹ã‚¿ã‚¤ãƒ«ã€ãƒ†ãƒ¼ãƒï¼‰ã‚’åæ˜ 
- é«˜å“è³ªãªãƒ—ãƒ­ä»•æ§˜ã®è¨˜è¿°
- è©³ç´°ã§å…·ä½“çš„ãªè¦ç´ æŒ‡å®š

### 4. å“è³ªä¿è¨¼
- offsetã€scaleã€rotationå€¤ã¯è«–ç†çš„ã«è¨­å®š
- è‰²æŒ‡å®šã¯å…·ä½“çš„ãªã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ä½¿ç”¨
- effectã€lightingç­‰ã¯ç¾å®Ÿçš„ãªå€¤ã‚’è¨­å®š

### 5. å‡ºåŠ›å½¢å¼ï¼ˆå¿…é ˆï¼‰
- **ãƒ™ãƒ¼ã‚¹YAMLã¨åŒã˜{total_lines}è¡Œ**ã§å‡ºåŠ›ï¼ˆæ§‹é€ ã¯ä¿æŒï¼‰
- ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã€é…åˆ—æ§‹é€ ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’å®Œå…¨ä¿æŒ
- ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ä¸è¦ã€YAMLã®ã¿ã‚’å‡ºåŠ›

## å¤‰æ›ä¾‹:
å…¥åŠ›: "YouTubeã‚µãƒ ãƒã‚¤ãƒ«ã€æ–™ç†ãƒãƒ£ãƒ³ãƒãƒ«"
- style: "YouTubeã‚µãƒ ãƒã‚¤ãƒ«ï¼ˆæ–™ç†ç³»ãƒãƒ£ãƒ³ãƒãƒ«ï¼‰" 
- theme_color: "#FF6B6B, #4ECDC4, #FFFFFF"ï¼ˆé£Ÿæ¬²ã‚’ããã‚‹é…è‰²ï¼‰
- main_texts[0].content: "è¶…ç°¡å˜ï¼10åˆ†ã§ä½œã‚Œã‚‹çµ¶å“ãƒ‘ã‚¹ã‚¿"
- background.type: "gradient"
- character.expression: "ç¬‘é¡”ã§æ–™ç†ã‚’æ¥½ã—ã‚“ã§ã„ã‚‹"

**æ³¨æ„: å…¨ã¦ã®{{AUTO_*}}ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’é©åˆ‡ãªå…·ä½“å€¤ã«ç½®æ›ã—ã€ãƒ—ãƒ­å“è³ªã®å®Œå…¨ãªYAMLã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚**"""
            
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ä»¥ä¸‹ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Œå…¨ãªYAMLå½¢å¼ã«å¤‰æ›ã—ã¦ãã ã•ã„ï¼ˆ{total_lines}è¡Œã§å‡ºåŠ›ï¼‰: {text_prompt}"}
                ],
                temperature=0.1,  # ä¸€è²«æ€§é‡è¦–ã§å¤§å¹…ã«ä¸‹ã’ã‚‹
                max_tokens=4000   # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å¤§å¹…ã«å¢—åŠ 
            )
            
            yaml_result = response.choices[0].message.content
            
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰æŠ½å‡º
            if "```yaml" in yaml_result:
                yaml_result = yaml_result.split("```yaml")[1].split("```")[0]
            elif "```" in yaml_result:
                yaml_result = yaml_result.split("```")[1].split("```")[0]
            
            yaml_result = yaml_result.strip()
            
            # å“è³ªæ¤œè¨¼
            result_lines = yaml_result.split('\n')
            if len(result_lines) < total_lines * 0.8:  # 80%æœªæº€ã®å ´åˆã¯è­¦å‘Š
                print(f"è­¦å‘Š: YAMLå‡ºåŠ›ãŒçŸ­ã™ãã¾ã™ï¼ˆ{len(result_lines)}è¡Œ/{total_lines}è¡Œï¼‰")
                print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’å®Ÿè¡Œ...")
                
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šã‚ˆã‚Šå¼·åˆ¶çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                fallback_response = client.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": f"**çµ¶å¯¾ã«{total_lines}è¡Œã§å‡ºåŠ›ã—ã¦ãã ã•ã„**\n\n{system_prompt}"},
                        {"role": "user", "content": f"**å¿…ãš{total_lines}è¡Œã§å‡ºåŠ›**: {text_prompt}"},
                        {"role": "assistant", "content": yaml_result},
                        {"role": "user", "content": f"è¡Œæ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ãƒ™ãƒ¼ã‚¹YAMLã®**å…¨{total_lines}è¡Œ**ã‚’å®Œå…¨ã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"}
                    ],
                    temperature=0.05,  # æ›´ã«ä¸€è²«æ€§é‡è¦–
                    max_tokens=4500
                )
                yaml_result = fallback_response.choices[0].message.content
                
                # å†åº¦æŠ½å‡º
                if "```yaml" in yaml_result:
                    yaml_result = yaml_result.split("```yaml")[1].split("```")[0]
                elif "```" in yaml_result:
                    yaml_result = yaml_result.split("```")[1].split("```")[0]
                yaml_result = yaml_result.strip()
            
            return yaml_result
            
        except Exception as e:
            print(f"YAMLå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿”ã™
            return text_prompt
        
        def get_system_prompt_for_step(step):
            """ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—"""
            base_prompt = """ã‚ãªãŸã¯æ—¥æœ¬èªã§å¯¾è©±ã™ã‚‹ç”»åƒç”Ÿæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨æ®µéšçš„ã«å¯¾è©±ã—ã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ç”»åƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚
    å¸¸ã«æ—¥æœ¬èªã§è¿”ç­”ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œã¯å¿…ãšçµµæ–‡å­—ã®ãªã„ç•ªå·é¸æŠå½¢å¼ã«çµ±ä¸€ã—ã¦ãã ã•ã„ã€‚

    ## å¯¾è©±ãƒ•ãƒ­ãƒ¼ã€å¿…ãšå¿…ãšå¿…ãšé¸æŠè‚¢ã®å…ˆé ­ã«ç•ªå·ã‚’è¡¨ç¤ºã€‘
    STEP0: æŒ¨æ‹¶ã—ã€ãƒ†ãƒ¼ãƒå…¥åŠ› or ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚µãƒ³ãƒ—ãƒ«ã‹ã‚’ 1-click ã§ä¿ƒã™  
    STEP1: ãƒ†ãƒ¼ãƒã‚’å—ã‘ãŸã‚‰ â†’ ç›®çš„ã«é©ã—ãŸãƒšãƒ«ã‚½ãƒŠã‚’ 5 ã¤æ—¥æœ¬èªã§ç”Ÿæˆ  
    STEP2: é¸æŠç•ªå·ã‚’å—ã‘ãŸã‚‰ â†’ ç”»åƒå†…ã‚³ãƒ”ãƒ¼ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰æ¡ˆã‚’5 å€‹æç¤º  
    STEP3: é¸æŠã‚’å—ã‘ãŸã‚‰ â†’ ã“ã‚Œã¾ã§ã®æ±ºå®šã‚’åŸºã«ã€ŒYAML_GENERATE:ã€ã«ç¶šã‘ã¦è©³ç´°è¦æ±‚ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡ºåŠ›ï¼ˆå¾Œã§convert_to_yaml_prompté–¢æ•°ãŒè‡ªå‹•å¤‰æ›ï¼‰
    STEP4: ã€Œ1: ã“ã®YAMLã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ç”»åƒç”Ÿæˆã‚¿ãƒ–ã§ä½¿ç”¨ã€ã€Œ2: YAMLã®å†…å®¹ã‚’ä¿®æ­£ã™ã‚‹ã€ã®äºŒæŠã‚’å‡ºã™  
    STEP5: 1 ãŒé¸ã°ã‚ŒãŸã‚‰ â†’ ã‚³ãƒ”ãƒ¼æ–¹æ³•ã¨ä½¿ç”¨æ‰‹é †ã‚’è©³ã—ãæ¡ˆå†…ã€2 ãŒé¸ã°ã‚ŒãŸã‚‰ â†’ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¿®æ­£è¦æ±‚ã‚’å—ã‘ã¦å†ãƒ«ãƒ¼ãƒ—

    ## YAML_GENERATEå‡ºåŠ›ãƒ«ãƒ¼ãƒ«ï¼ˆSTEP3å°‚ç”¨ï¼‰
    STEP3ã§ã¯ã€ŒYAML_GENERATE:ã€ã®å¾Œã«ä»¥ä¸‹ã®å½¢å¼ã§è©³ç´°ãªãƒ†ã‚­ã‚¹ãƒˆè¦æ±‚ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

    **å½¢å¼ä¾‹**:
    YAML_GENERATE: YouTubeã‚µãƒ ãƒã‚¤ãƒ«ã€ã‚¨ãƒ³ã‚¿ãƒ¡ç³»ãƒãƒ£ãƒ³ãƒãƒ«ã€ã€Œçˆ†ç¬‘å¿…è‡³ï¼ä»Šæ—¥ã®æŒ‘æˆ¦ã¯ã“ã‚Œã ï¼ã€ã¨ã„ã†ãƒ¡ã‚¤ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€ãƒãƒƒãƒ—ã§ã‚«ãƒ©ãƒ•ãƒ«ãªãƒ‡ã‚¶ã‚¤ãƒ³ã€æ˜ã‚‹ã„é»„è‰²ã¨ã‚ªãƒ¬ãƒ³ã‚¸ã®é…è‰²ã€è³‘ã‚„ã‹ã§æ¥½ã—ã’ãªèƒŒæ™¯ã€å…ƒæ°—ã„ã£ã±ã„ã®YouTuberãŒæ¥½ã—ã‚“ã§ã„ã‚‹æ§˜å­ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼

    ## é‡è¦ãªæ³¨æ„äº‹é …
    - YAML_GENERATE:ã®å¾Œã¯**YAMLå½¢å¼ã§ã¯ãªãè‡ªç„¶ãªæ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆ**ã§å‡ºåŠ›
    - è©³ç´°è¦æ±‚ãƒ†ã‚­ã‚¹ãƒˆã«ã¯ä»¥ä¸‹ã‚’å«ã‚ã‚‹ï¼š
      * ç”»åƒã®ç›®çš„ãƒ»ç”¨é€”
      * ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»é›°å›²æ°—
      * ãƒ¡ã‚¤ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹
      * é…è‰²ãƒ»ãƒ†ãƒ¼ãƒã‚«ãƒ©ãƒ¼
      * èƒŒæ™¯ã®é›°å›²æ°—
      * ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ»äººç‰©ã®æå†™
      * ãã®ä»–ã®é‡è¦ãªè¦ç´ 
    - **çµ¶å¯¾ã«YAMLå½¢å¼ï¼ˆkey: valueï¼‰ã§ã¯å‡ºåŠ›ã—ãªã„**
    - convert_to_yaml_prompté–¢æ•°ãŒè‡ªå‹•çš„ã«89-110è¡Œã®å®Œå…¨ãªYAMLã«å¤‰æ›ã™ã‚‹

    ## ãµã‚‹ã¾ã„æŒ‡é‡
    - è³ªå•ãŒã‚ã„ã¾ã„ãªã‚‰ 1 åº¦ã ã‘èãè¿”ã™
    - ä¾é ¼ãŒè‹±æ–‡ã§ã‚‚å‡ºåŠ›ã¯æ—¥æœ¬èª
    - é‡è¦ãƒ†ã‚­ã‚¹ãƒˆãŒåˆ‡ã‚Œãªã„ã‚ˆã†é…æ…®

    ## çµ¶å¯¾ã«å®ˆã‚‹ãƒ«ãƒ¼ãƒ«
    1. **é¸æŠè‚¢ã¯å¿…ãšã€Œ1: é¸æŠè‚¢Aã€ã€Œ2: é¸æŠè‚¢Bã€ã®å½¢å¼ã§ç•ªå·ã‚’å…ˆé ­ã«ä»˜ã‘ã‚‹**
    2. **ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç•ªå·ã§é¸æŠã™ã‚‹ã¾ã§æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«é€²ã¾ãªã„**
    3. **STEP3ã§YAML_GENERATE:ã®å¾Œã¯è©³ç´°ãªæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼ˆYAMLå½¢å¼ç¦æ­¢ï¼‰**
    4. **æ›–æ˜§ãªå›ç­”ï¼ˆã€ŒãŠä»»ã›ã€ãªã©ï¼‰ã«ã¯å…·ä½“çš„ãªé¸æŠè‚¢ã‚’å†æç¤º**
    5. **YAML_GENERATE:ã®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã¯éå¸¸ã«è©³ç´°ã§å…·ä½“çš„ã«è¨˜è¿°ã™ã‚‹**

    ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—: STEP{step}"""

            return base_prompt
        
        def get_history_images():
            """å±¥æ­´ç”»åƒå–å¾—ï¼ˆè»½é‡åŒ–ï¼‰"""
            if not app_state['generation_history']:
                return []
            
            recent = app_state['generation_history'][-3:]  # æœ€æ–°3ä»¶ã®ã¿ï¼ˆè»½é‡åŒ–ï¼‰
            images = []
            
            for item in reversed(recent):
                try:
                    image = Image.open(BytesIO(item['image_data']))
                    images.append(image)
                except:
                    continue
            
            return images
        
        # ã‚¢ãƒ—ãƒªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹ç¯‰
        with gr.Blocks(title=APP_CONFIG['title'], css=get_app_css(), theme=gr.themes.Base()) as app:
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼
            gr.HTML(f"""
                <div style="text-align: center; padding: 1rem 0; border-bottom: 1px solid #333; margin-bottom: 1rem;">
                    <h1 style="color: #ffffff; font-size: 1.8rem; margin: 0;">{APP_CONFIG['title']}</h1>
                </div>
            """)
            
            # ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
            with gr.Row():
                # å·¦å´ï¼šè¨­å®šï¼ˆ35%ï¼‰
                with gr.Column(scale=35):
                    # APIã‚­ãƒ¼è¨­å®š
                    with gr.Accordion("ğŸ”‘ APIè¨­å®š", open=True):
                        # HuggingFace Spacesç’°å¢ƒå¤‰æ•°å¯¾å¿œ
                        default_api_key = os.getenv("OPENAI_API_KEY", "")
                        api_key = gr.Textbox(
                            label="OpenAI APIã‚­ãƒ¼",
                            placeholder="sk-...",
                            type="password",
                            value=default_api_key,
                            info="ç’°å¢ƒå¤‰æ•°OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯è‡ªå‹•å…¥åŠ›ã•ã‚Œã¾ã™"
                        )
                    
                    # åŸºæœ¬è¨­å®š
                    with gr.Accordion("âš™ï¸ åŸºæœ¬è¨­å®š", open=True):
                        with gr.Row():
                            size = gr.Dropdown(
                                label="ã‚µã‚¤ã‚º",
                                choices=["1024x1024 (æ­£æ–¹å½¢)", "1024x1536 (ç¸¦é•·)", "1536x1024 (æ¨ªé•·)"],
                                value="1024x1024 (æ­£æ–¹å½¢)"
                            )
                            quality = gr.Dropdown(
                                label="å“è³ª",
                                choices=["auto", "low", "medium", "high"],
                                value="auto"
                            )
                        
                        with gr.Row():
                            format_option = gr.Dropdown(
                                label="å½¢å¼",
                                choices=["png", "jpeg", "webp"],
                                value="png"
                            )
                            transparent_bg = gr.Checkbox(
                                label="ğŸ­ é€æ˜èƒŒæ™¯",
                                value=False
                            )
                        
                        with gr.Row():
                            compression_slider = gr.Slider(
                                label="åœ§ç¸®ç‡ (JPEG/WebP)",
                                minimum=0,
                                maximum=100,
                                value=APP_CONFIG['default_compression'],
                                step=5,
                                visible=False
                            )
                        
                        with gr.Row():
                            moderation_dropdown = gr.Dropdown(
                                label="ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼",
                                choices=[("æ¨™æº–ï¼ˆæ¨å¥¨ï¼‰", "auto"), ("åˆ¶é™ç·©å’Œï¼ˆã‚¢ãƒ¼ãƒˆãƒ»åŒ»ç™‚ãƒ»æ•™è‚²ç”¨ï¼‰", "low")],
                                value="auto",
                                info="äººä½“è¡¨ç¾ãƒ»æš´åŠ›çš„è¡¨ç¾ãªã©ã®åˆ¶é™ãƒ¬ãƒ™ãƒ«ã€‚ã‚¢ãƒ¼ãƒˆåˆ¶ä½œãƒ»åŒ»ç™‚ãƒ»æ•™è‚²ç”¨é€”ã¯ã€Œåˆ¶é™ç·©å’Œã€ã‚’é¸æŠ"
                            )
                        
                        with gr.Row():
                            image_count_slider = gr.Slider(
                                label="ç”»åƒæ•°",
                                minimum=1,
                                maximum=4,
                                value=1,
                                step=1,
                                info="åŒæ™‚ã«ç”Ÿæˆã™ã‚‹ç”»åƒã®æšæ•°ï¼ˆå¤šã„ã»ã©æ™‚é–“ãƒ»ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚Šã¾ã™ï¼‰"
                            )
                        
                        use_ai_mode = gr.Checkbox(
                            label="âš¡ AIæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰",
                            value=True
                        )
                        
                        enable_responses_api = gr.Checkbox(
                            label="ğŸ’¬ å¯¾è©±å‹æœ‰åŠ¹ï¼ˆResponses APIä½¿ç”¨ï¼‰",
                            value=False,
                            info="å¯¾è©±å‹ç·¨é›†ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã“ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„"
                        )
                    
                    # ã‚¿ãƒ–
                    with gr.Tabs():
                        with gr.Tab("âœï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›´æ¥"):
                            prompt = gr.Textbox(
                                label="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                                placeholder="ç¾ã—ã„å±±ã®å¤•æ—¥ã€ãƒ•ã‚©ãƒˆãƒªã‚¢ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã€é«˜å“è³ª",
                                lines=6
                            )
                            
                            direct_btn = gr.Button("ğŸš€ ç”»åƒç”Ÿæˆ", variant="primary", size="lg")
                        
                        with gr.Tab("ğŸ–¼ï¸ ç”»åƒå‚ç…§ç”Ÿæˆ"):
                            gr.Markdown("""
                            ### ç”»åƒå‚ç…§ç”Ÿæˆ
                            å‚ç…§ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ãã®ç”»åƒã®ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»æ§‹å›³ãƒ»é›°å›²æ°—ã‚’å‚è€ƒã«æ–°ã—ã„ç”»åƒã‚’ç”Ÿæˆã—ã¾ã™ã€‚
                            
                            **ä¾‹**: çŠ¬ã®å†™çœŸ + ã€ŒçŒ«ãŒå¸½å­ã‚’ã‹ã¶ã£ã¦ã„ã‚‹ã€ â†’ çŠ¬ã®å†™çœŸã®ã‚¹ã‚¿ã‚¤ãƒ«ã§çŒ«ãŒå¸½å­ã‚’ã‹ã¶ã£ãŸç”»åƒ
                            """)
                            
                            reference_image = gr.Image(
                                label="å‚ç…§ç”»åƒ",
                                type="pil",
                                height=200,
                                image_mode="RGB",
                                sources=["upload", "clipboard"]
                            )
                            
                            reference_prompt = gr.Textbox(
                                label="ç”Ÿæˆã—ãŸã„å†…å®¹",
                                placeholder="ä¾‹: çŒ«ãŒå¸½å­ã‚’ã‹ã¶ã£ã¦ã„ã‚‹ã€ç¾ã—ã„é¢¨æ™¯ã€ãƒ¢ãƒ€ãƒ³ãªãƒ­ã‚´",
                                lines=3
                            )
                            
                            reference_generate_btn = gr.Button("ğŸ–¼ï¸ å‚ç…§ç”»åƒã§ç”Ÿæˆ", variant="primary", size="lg")
                        
                        with gr.Tab("ğŸ¤– AIãƒãƒ£ãƒƒãƒˆ"):
                            gr.Markdown("""
                            ### ğŸ¤– AIç”»åƒç”Ÿæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
                            å¯¾è©±å½¢å¼ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚æ®µéšçš„ã«ãƒ†ãƒ¼ãƒâ†’ãƒšãƒ«ã‚½ãƒŠâ†’ã‚³ãƒ”ãƒ¼ã‚’æ±ºã‚ã¦ã„ãã¾ã™ã€‚
                            """)
                            
                            # ãƒãƒ£ãƒƒãƒˆã‚¨ãƒªã‚¢
                            ai_chatbot = gr.Chatbot(
                                label="AIå¯¾è©±",
                                height=400,
                                type="messages", 
                                value=[]
                            )
                            
                            with gr.Row():
                                ai_message_input = gr.Textbox(
                                    label="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›",
                                    placeholder="ä½•ã‚’ä½œã‚ŠãŸã„ã§ã™ã‹ï¼Ÿï¼ˆä¾‹ï¼šYouTubeã‚µãƒ ãƒã‚¤ãƒ«ã€InstagramæŠ•ç¨¿ç”»åƒï¼‰",
                                    scale=4,
                                    lines=2,
                                    info="Shift+Enterã§é€ä¿¡"
                                )
                                ai_send_btn = gr.Button("é€ä¿¡\n(Shift+Enter)", variant="primary", scale=1)
                            
                            # ä½¿ç”¨æ–¹æ³•ã®æ¡ˆå†…
                            gr.Markdown("""
                            ### ğŸ“‹ ç”Ÿæˆã•ã‚ŒãŸYAMLãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½¿ç”¨æ–¹æ³•
                            1. å¯¾è©±å®Œäº†å¾Œã€YAMLã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼
                            2. ã€ŒğŸ“‹ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›†ã€ã‚¨ãƒªã‚¢ã«ãƒšãƒ¼ã‚¹ãƒˆ  
                            3. ã€Œâœï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›´æ¥ã€ã‚¿ãƒ–ã§ç”»åƒç”Ÿæˆ
                            """)
                            
                            with gr.Row():
                                ai_clear_btn = gr.Button("ğŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆã‚¯ãƒªã‚¢", variant="secondary")
                                ai_restart_btn = gr.Button("ğŸ”„ æœ€åˆã‹ã‚‰", variant="secondary")
                        
                
                # ä¸­å¤®ï¼šç”»åƒè¡¨ç¤ºï¼ˆ40%ï¼‰
                with gr.Column(scale=40):
                    output_image = gr.Image(label="ç”Ÿæˆç”»åƒ", height=400)
                    status_display = gr.Markdown("ğŸ“¸ ç”»åƒç”Ÿæˆã®æº–å‚™å®Œäº†")
                    cost_info = gr.Markdown("**ç”Ÿæˆæƒ…å ±**\\nå¾…æ©Ÿä¸­...")
                    
                    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¡¨ç¤ºã¨ã‚³ãƒ”ãƒ¼
                    with gr.Accordion("ğŸ“‹ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›†", open=False):
                        prompt_display = gr.Textbox(
                            label="ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç·¨é›†å¯èƒ½ï¼‰",
                            placeholder="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™",
                            lines=8,
                            interactive=True,
                            show_copy_button=True
                        )
                        with gr.Row():
                            regenerate_btn = gr.Button("ğŸ”„ ç·¨é›†ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å†ç”Ÿæˆ", variant="primary")
                            reset_prompt_btn = gr.Button("â†©ï¸ å…ƒã«æˆ»ã™", variant="secondary")
                    
                    # å¯¾è©±å‹ç·¨é›†æ©Ÿèƒ½
                    with gr.Accordion("ğŸ’¬ å¯¾è©±å‹ç·¨é›†", open=False):
                        gr.Markdown("""
                        ### ç”Ÿæˆç”»åƒã¨ã®å¯¾è©±
                        - **ç¶™ç¶šç·¨é›†**: ç¾åœ¨ã®ç”»åƒã‚’ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ ã®å¤‰æ›´ã‚’æŒ‡ç¤º
                        - **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¿æŒ**: å‰å›ã®ç”Ÿæˆå†…å®¹ã‚’è¦šãˆã¦æ”¹å–„
                        - **ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–**: ç´°ã‹ã„èª¿æ•´ã‚„è¿½åŠ è¦æ±‚ãŒå¯èƒ½
                        
                        **åˆ©ç”¨æ¡ä»¶**: ã€ŒğŸ’¬ å¯¾è©±å‹æœ‰åŠ¹ã€ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ç”Ÿæˆã•ã‚ŒãŸç”»åƒ
                        """)
                        
                        interactive_prompt = gr.Textbox(
                            label="è¿½åŠ ã®æŒ‡ç¤ºãƒ»å¤‰æ›´ç‚¹",
                            placeholder="ä¾‹: ç©ºã‚’é’ç©ºã«å¤‰æ›´ã€å»ºç‰©ã‚’è¿½åŠ ã€è‰²èª¿ã‚’æš–ã‹ãã™ã‚‹",
                            lines=3
                        )
                        
                        with gr.Row():
                            continue_btn = gr.Button("ğŸ”„ å¯¾è©±å‹ç·¨é›†", variant="primary")
                            reset_context_btn = gr.Button("ğŸ—‘ï¸ å±¥æ­´ãƒªã‚»ãƒƒãƒˆ", variant="secondary")
                        
                        interactive_status = gr.Markdown("ğŸ’¬ ç”»åƒã‚’ç”Ÿæˆå¾Œã€å¯¾è©±å‹ç·¨é›†ãŒåˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã™")
                    
                    # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³
                    with gr.Row():
                        pass  # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’å‰Šé™¤
                
                # å³å´ï¼šå±¥æ­´ï¼ˆ25%ï¼‰
                with gr.Column(scale=25):
                    with gr.Accordion("ğŸ“š å±¥æ­´", open=True):
                        history_gallery = gr.Gallery(
                            label="æœ€è¿‘ã®ç”Ÿæˆ",
                            columns=1,
                            rows=3,
                            height="auto"
                        )
                        refresh_btn = gr.Button("ğŸ”„ æ›´æ–°", size="sm")
            
            # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç›´æ¥ç”Ÿæˆ
            direct_btn.click(
                generate_from_prompt_fast,
                inputs=[api_key, prompt, size, quality, format_option, transparent_bg, compression_slider, moderation_dropdown, image_count_slider, enable_responses_api],
                outputs=[output_image, status_display, cost_info, prompt_display]
            ).then(
                get_history_images,
                outputs=[history_gallery]
            )
            
            # å‚ç…§ç”»åƒç”Ÿæˆ
            reference_generate_btn.click(
                generate_with_reference_image_fast,
                inputs=[api_key, reference_image, reference_prompt, size, quality, format_option, transparent_bg, compression_slider, moderation_dropdown],
                outputs=[output_image, status_display, cost_info, prompt_display]
            ).then(
                get_history_images,
                outputs=[history_gallery]
            )
            
            # AIãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ï¼ˆã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆæ–¹å¼ï¼‰
            def ai_chat_simple(api_key, message, chat_history, current_size):
                """AIãƒãƒ£ãƒƒãƒˆï¼ˆã‚³ãƒ”ãƒ¼&ãƒšãƒ¼ã‚¹ãƒˆæ–¹å¼ï¼‰"""
                # ã‚µã‚¤ã‚ºæƒ…å ±ã‚’app_stateã«ä¿å­˜
                app_state['current_size'] = current_size
                new_chat_history, cleared_message = ai_chat_response(api_key, message, chat_history)
                return new_chat_history, cleared_message
            
            # AIãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½
            ai_send_btn.click(
                ai_chat_simple,
                inputs=[api_key, ai_message_input, ai_chatbot, size],
                outputs=[ai_chatbot, ai_message_input]
            )
            
            ai_message_input.submit(
                ai_chat_simple,
                inputs=[api_key, ai_message_input, ai_chatbot, size],
                outputs=[ai_chatbot, ai_message_input]
            )
            
            
            # AIãƒãƒ£ãƒƒãƒˆã‚¯ãƒªã‚¢
            ai_clear_btn.click(
                lambda: [],
                outputs=[ai_chatbot]
            )
            
            # AIãƒãƒ£ãƒƒãƒˆå†é–‹
            def ai_chat_restart():
                """AIãƒãƒ£ãƒƒãƒˆã‚’æœ€åˆã‹ã‚‰é–‹å§‹"""
                welcome_msg = """ğŸ¨ **AIç”»åƒç”Ÿæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ** ã¸ã‚ˆã†ã“ãï¼

æ®µéšçš„ãªå¯¾è©±ã§ã€ã‚ãªãŸã®ç†æƒ³ã®ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚

**ä»Šæ—¥ã¯ä½•ã‚’ä½œã‚Šã¾ã™ã‹ï¼Ÿ**

1: YouTubeã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒ
2: InstagramæŠ•ç¨¿ç”¨ç”»åƒ  
3: ãƒ–ãƒ­ã‚°ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒç”»åƒ
4: ãƒ­ã‚´ãƒ‡ã‚¶ã‚¤ãƒ³
5: è‡ªç”±ã«ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›

ç•ªå·ã‚’é¸ã¶ã‹ã€ä½œã‚ŠãŸã„ã‚‚ã®ã‚’è‡ªç”±ã«å…¥åŠ›ã—ã¦ãã ã•ã„ï¼"""
                
                return [{"role": "assistant", "content": welcome_msg}]
            
            ai_restart_btn.click(
                ai_chat_restart,
                outputs=[ai_chatbot]
            )
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚³ãƒ”ãƒ¼ï¼ˆå‰Šé™¤ï¼‰
            # copy_btnã¯å­˜åœ¨ã—ãªã„ã®ã§ã‚¹ã‚­ãƒƒãƒ—
            
            # å±¥æ­´æ›´æ–°
            refresh_btn.click(get_history_images, outputs=[history_gallery])
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†ç”Ÿæˆ
            def regenerate_with_edited_prompt(api_key, edited_prompt, enable_responses_api):
                """ç·¨é›†ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å†ç”Ÿæˆ"""
                if not edited_prompt.strip():
                    return None, "âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "", ""
                
                print(f"[DEBUG] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†ç”Ÿæˆ: enable_responses_api={enable_responses_api}")
                
                # ç¾åœ¨ã®è¨­å®šã‚’ä½¿ç”¨ã—ã¦å†ç”Ÿæˆï¼ˆã‚µã‚¤ã‚ºã€å“è³ªç­‰ã¯æœ€å¾Œã®è¨­å®šã‚’ä½¿ç”¨ï¼‰
                return generate_from_prompt_fast(api_key, edited_prompt, "1024x1024 (æ­£æ–¹å½¢)", "auto", "png", False, APP_CONFIG['default_compression'], "auto", 1, enable_responses_api)
            
            regenerate_btn.click(
                regenerate_with_edited_prompt,
                inputs=[api_key, prompt_display, enable_responses_api],
                outputs=[output_image, status_display, cost_info, prompt_display]
            ).then(
                get_history_images,
                outputs=[history_gallery]
            )
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒªã‚»ãƒƒãƒˆ
            def reset_to_original():
                """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…ƒã«æˆ»ã™"""
                original = app_state.get('original_prompt', '')
                return original
            
            reset_prompt_btn.click(
                reset_to_original,
                outputs=[prompt_display]
            )
            
            # å¯¾è©±å‹ç·¨é›†
            continue_btn.click(
                continue_interactive_editing,
                inputs=[api_key, interactive_prompt, interactive_status],
                outputs=[output_image, status_display, cost_info, interactive_status]
            ).then(
                get_history_images,
                outputs=[history_gallery]
            )
            
            # å¯¾è©±å‹ç·¨é›†å±¥æ­´ãƒªã‚»ãƒƒãƒˆ
            reset_context_btn.click(
                reset_interactive_context,
                outputs=[interactive_status]
            )
            
            # å½¢å¼å¤‰æ›´æ™‚ã®UIæ›´æ–°
            def update_compression_visibility(format_opt):
                return gr.update(visible=(format_opt in ["jpeg", "webp"]))
            
            format_option.change(
                update_compression_visibility,
                inputs=[format_option],
                outputs=[compression_slider]
            )
        
        return app

# HuggingFace Spacesç”¨ã®ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨
if __name__ == "__main__":
    app = create_optimized_app()
    app.launch(
        # HuggingFace Spacesç”¨è¨­å®š
        show_error=True,
        show_tips=False,
        quiet=False
    )